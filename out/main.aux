\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces fraction of FLOPs spent in attention versus MLP changes with scale.}}{1}{figure.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Emergent Abilities of Large Language Models}}{1}{figure.1.2}\protected@file@percent }
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Overview and Tokenization}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@starttoc{chapters@1}}
\newmarginnote{note.1.1}{{1}{2752512sp}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Why this course exists}{1}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}The industrialization of language models }{1}{subsection.1.1.1}\protected@file@percent }
\newlabel{def:FLOPs-FLOPS}{{1.1.1}{1}{The industrialization of language models }{tcb@cnt@Definition.1}{}}
\newlabel{def:FLOPs-FLOPS@cref}{{[subsection][1][1,1]1.1.1}{[1][1][]1}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}What can we learn in this class that transfers to frontier models? }{2}{subsection.1.1.2}\protected@file@percent }
\ttl@writefile{ptc}{\ttl@stoptoc{chapters@1}}
\ttl@writefile{ptc}{\ttl@starttoc{chapters@2}}
\newmarginnote{note.3.1}{{3}{2752512sp}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Current Landscape}{3}{section.1.2}\protected@file@percent }
\ttl@writefile{ptc}{\ttl@stoptoc{chapters@2}}
\ttl@writefile{ptc}{\ttl@starttoc{chapters@3}}
\newmarginnote{note.5.1}{{5}{2752512sp}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Course Components}{5}{section.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Design Decisions}}{5}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:design decisions}{{1.3}{5}{Design Decisions}{figure.caption.1}{}}
\newlabel{fig:design decisions@cref}{{[figure][3][1]1.3}{[1][5][]5}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Tokenizer Example}}{6}{figure.1.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Transformer}}{6}{figure.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Basics}{6}{subsection.1.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Tokenization}{6}{subsection.1.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Architecture}{6}{tcb@cnt@Definition.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Training}{6}{figure.1.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces GPU Kernels}}{7}{figure.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Systems}{7}{subsection.1.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Kernels}{7}{subsection.1.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces Memory ä¸ Computeä¹‹é—´çš„æ•°æ®ä¼ è¾“å¸¦å®½å¼€é”€ç¤ºæ„}}{7}{figure.caption.2}\protected@file@percent }
\newlabel{fig:bandwidth-cost}{{1.7}{7}{Memory ä¸ Computeä¹‹é—´çš„æ•°æ®ä¼ è¾“å¸¦å®½å¼€é”€ç¤ºæ„}{figure.caption.2}{}}
\newlabel{fig:bandwidth-cost@cref}{{[figure][7][1]1.7}{[1][7][]7}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Inference}}{8}{figure.1.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Parallelism}{8}{figure.caption.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Inference}{8}{figure.caption.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}Scaling Laws}{9}{subsection.1.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces Scaling Laws}}{9}{figure.caption.3}\protected@file@percent }
\newlabel{fig:scaling laws}{{1.9}{9}{Scaling Laws}{figure.caption.3}{}}
\newlabel{fig:scaling laws@cref}{{[figure][9][1]1.9}{[1][9][]9}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.4}Data}{9}{subsection.1.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces Composition of Data}}{9}{figure.caption.4}\protected@file@percent }
\newlabel{fig:data}{{1.10}{9}{Composition of Data}{figure.caption.4}{}}
\newlabel{fig:data@cref}{{[figure][10][1]1.10}{[1][9][]9}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{Evaluation}{9}{figure.caption.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.11}{\ignorespaces SFT Code ç¤ºæ„}}{10}{figure.1.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Data curation}{10}{figure.caption.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Data processing}{10}{figure.caption.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.5}Alignment}{10}{subsection.1.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Supervised Fine-Tuning (SFT)}{10}{figure.1.11}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.12}{\ignorespaces Learn from feedbackç¤ºæ„ }}{11}{figure.1.12}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Learning from Feedback}{11}{figure.1.11}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.14}{\ignorespaces GPT-2 Tokenizer}}{12}{figure.1.14}\protected@file@percent }
\ttl@writefile{ptc}{\ttl@stoptoc{chapters@3}}
\ttl@writefile{ptc}{\ttl@starttoc{chapters@4}}
\newmarginnote{note.12.1}{{12}{13468164sp}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Tokenization}{12}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Intro}{12}{subsection.1.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}Observations}{12}{subsection.1.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.13}{\ignorespaces Tokenization}}{12}{figure.caption.6}\protected@file@percent }
\newlabel{fig:Tokenize}{{1.13}{12}{Tokenization}{figure.caption.6}{}}
\newlabel{fig:Tokenize@cref}{{[figure][13][1]1.13}{[1][12][]12}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.15}{\ignorespaces Character-based tokenization}}{13}{figure.1.15}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.16}{\ignorespaces Byte-based tokenization}}{13}{figure.1.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.3}Character Tokenizer}{13}{subsection.1.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Problems}{13}{figure.1.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.4}Byte Tokenizer}{13}{subsection.1.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Drawback}{13}{figure.1.16}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.17}{\ignorespaces Word-based tokenization}}{14}{figure.1.17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.5}Word Tokenizer}{14}{subsection.1.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Drawback:}{14}{figure.1.17}\protected@file@percent }
\newmarginnote{note.14.1}{{14}{13468164sp}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.6}BPE Tokenizer}{14}{subsection.1.4.6}\protected@file@percent }
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Byte $-$ Pair Encoding}}{14}{algocf.1}\protected@file@percent }
\newlabel{alg:bpe}{{1}{14}{BPE Tokenizer}{algocf.1}{}}
\newlabel{alg:bpe@cref}{{[algocf][1][]1}{[1][14][]14}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.7}Tokenizer Properties}{16}{subsection.1.4.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{There are three major groups of design choices that determine how the tokenizer will break down text:}{16}{subsection.1.4.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{The tokenization method}{16}{Item.15}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{The initialization parameters}{16}{Item.15}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{The domain of the data the tokenizer targets}{16}{Item.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.8}Summary of Tokenization Methods}{17}{subsection.1.4.8}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {2}PyTorch, Resource Accounting}{19}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{chapters@4}}
\ttl@writefile{ptc}{\ttl@starttoc{chapters@5}}
\newmarginnote{note.19.1}{{19}{2752512sp}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Original Transformer}{19}{section.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces The Transformer-model architecture}}{19}{figure.caption.8}\protected@file@percent }
\newlabel{fig: Transformer architecture}{{2.1}{19}{The Transformer-model architecture}{figure.caption.8}{}}
\newlabel{fig: Transformer architecture@cref}{{[figure][1][2]2.1}{[1][19][]19}{}{}{}}
\ttl@writefile{ptc}{\ttl@stoptoc{chapters@5}}
\ttl@writefile{ptc}{\ttl@starttoc{chapters@6}}
\newmarginnote{note.21.1}{{21}{2752512sp}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Input Embedding}{21}{subsection.2.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Input $\xrightarrow  {}$ Tokens $\xrightarrow  {}$ Embedding Vectors}}{21}{figure.caption.9}\protected@file@percent }
\newlabel{fig:Input Embedding Box}{{2.2}{21}{Input $\xrightarrow {}$ Tokens $\xrightarrow {}$ Embedding Vectors}{figure.caption.9}{}}
\newlabel{fig:Input Embedding Box@cref}{{[figure][2][2]2.2}{[1][21][]21}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{Tokenization}{21}{figure.caption.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Embedding}{21}{figure.caption.9}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{1. Static Token Embeddings vs. Contextualized Embeddings}{21}{tcb@cnt@Definition.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces A language model operates on raw, static embeddings as its input and produces contextual text embeddings.}}{22}{figure.2.4}\protected@file@percent }
\newlabel{fig:static-embedding}{{2.3a}{22}{Static Embedding}{figure.caption.10}{}}
\newlabel{fig:static-embedding@cref}{{[subfigure][1][2,3]2.3a}{[1][21][]22}{}{}{}}
\newlabel{sub@fig:static-embedding}{{a}{22}{Static Embedding}{figure.caption.10}{}}
\newlabel{sub@fig:static-embedding@cref}{{[subfigure][1][2,3]2.3a}{[1][21][]22}{}{}{}}
\newlabel{fig:contextualized-embedding}{{2.3b}{22}{Contextualized Embedding}{figure.caption.10}{}}
\newlabel{fig:contextualized-embedding@cref}{{[subfigure][2][2,3]2.3b}{[1][21][]22}{}{}{}}
\newlabel{sub@fig:contextualized-embedding}{{b}{22}{Contextualized Embedding}{figure.caption.10}{}}
\newlabel{sub@fig:contextualized-embedding@cref}{{[subfigure][2][2,3]2.3b}{[1][21][]22}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces é™æ€åµŒå…¥ vs. ä¸Šä¸‹æ–‡åŒ–åµŒå…¥å¯¹æ¯”}}{22}{figure.caption.10}\protected@file@percent }
\newlabel{fig:embeddings-comparison}{{2.3}{22}{é™æ€åµŒå…¥ vs. ä¸Šä¸‹æ–‡åŒ–åµŒå…¥å¯¹æ¯”}{figure.caption.10}{}}
\newlabel{fig:embeddings-comparison@cref}{{[figure][3][2]2.3}{[1][21][]22}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{2. Text and Sentence Embeddings}{22}{figure.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{3. Word2Vec}{22}{tcb@cnt@Definition.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces CBOWå’ŒSkip-gram architectureç¤ºæ„å›¾}}{22}{figure.caption.11}\protected@file@percent }
\newlabel{fig:Word2Vec}{{2.5}{22}{CBOWå’ŒSkip-gram architectureç¤ºæ„å›¾}{figure.caption.11}{}}
\newlabel{fig:Word2Vec@cref}{{[figure][5][2]2.5}{[1][22][]22}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces ä½ç½®ç¼–ç ç¤ºæ„å›¾}}{23}{figure.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Positional Encoding}{23}{subsection.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{1.å›ºå®šæ­£ä½™å¼¦ä½ç½®ç¼–ç ï¼ˆVaswaniåŸç‰ˆï¼‰}{23}{subsection.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{2.å¯å­¦ä¹ ä½ç½®ç¼–ç }{23}{Item.23}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces ä¸¤ç§å¸¸è§ä½ç½®ç¼–ç æ–¹æ³•çš„æ¯”è¾ƒ}}{23}{table.caption.12}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Transdormer Encoder Block from Vaswani et al. (2017)}}{24}{figure.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Encoder ç»“æ„}{24}{subsection.2.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Transformer Encoder Block from Vaswani et al. (2017)}}{24}{figure.caption.13}\protected@file@percent }
\newlabel{fig:Transformer Encoder Block}{{2.8}{24}{Transformer Encoder Block from Vaswani et al. (2017)}{figure.caption.13}{}}
\newlabel{fig:Transformer Encoder Block@cref}{{[figure][8][2]2.8}{[1][24][]24}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{å¤šå¤´è‡ªæ³¨æ„æœºåˆ¶}{24}{figure.caption.13}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces We get better LLMs by doing attention multiple times in parallel, increasing the modelâ€™s capacity to attend to different types of information.}}{24}{figure.caption.14}\protected@file@percent }
\newlabel{fig:Multi-Head Attention}{{2.9}{24}{We get better LLMs by doing attention multiple times in parallel, increasing the modelâ€™s capacity to attend to different types of information}{figure.caption.14}{}}
\newlabel{fig:Multi-Head Attention@cref}{{[figure][9][2]2.9}{[1][24][]24}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Multi-Head Self-Attentionè®¡ç®—å›¾}}{25}{figure.caption.15}\protected@file@percent }
\newlabel{fig:Multi-Head Self-Attentionè®¡ç®—å›¾}{{2.10}{25}{Multi-Head Self-Attentionè®¡ç®—å›¾}{figure.caption.15}{}}
\newlabel{fig:Multi-Head Self-Attentionè®¡ç®—å›¾@cref}{{[figure][10][2]2.10}{[1][25][]25}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{Step0:è¿›è¡ŒSelf-Attentionä¹‹å‰çš„è¾“å…¥å’ŒæŠ•å½±çŸ©é˜µ}{26}{equation.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Step0:è¿›è¡ŒSelf-Attentionä¹‹å‰çš„è¾“å…¥å’ŒæŠ•å½±çŸ©é˜µ}}{26}{figure.caption.16}\protected@file@percent }
\newlabel{fig:Step0:è¿›è¡ŒSelf-Attentionä¹‹å‰çš„è¾“å…¥å’ŒæŠ•å½±çŸ©é˜µ}{{2.11}{26}{Step0:è¿›è¡ŒSelf-Attentionä¹‹å‰çš„è¾“å…¥å’ŒæŠ•å½±çŸ©é˜µ}{figure.caption.16}{}}
\newlabel{fig:Step0:è¿›è¡ŒSelf-Attentionä¹‹å‰çš„è¾“å…¥å’ŒæŠ•å½±çŸ©é˜µ@cref}{{[figure][11][2]2.11}{[1][26][]26}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{Step1:æ ¹æ®æŠ•å½±çŸ©é˜µæ›´æ–°$Q$,$K$,$V$}{27}{figure.caption.16}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Step1:æ ¹æ®æŠ•å½±çŸ©é˜µæ›´æ–°$Q$,$K$,$V$}}{27}{figure.caption.17}\protected@file@percent }
\newlabel{fig:Step1:æ ¹æ®æŠ•å½±çŸ©é˜µæ›´æ–°$Q$,$K$,$V$}{{2.12}{27}{Step1:æ ¹æ®æŠ•å½±çŸ©é˜µæ›´æ–°$Q$,$K$,$V$}{figure.caption.17}{}}
\newlabel{fig:Step1:æ ¹æ®æŠ•å½±çŸ©é˜µæ›´æ–°$Q$,$K$,$V$@cref}{{[figure][12][2]2.12}{[1][27][]27}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces Teacher Forcing ç¤ºæ„å›¾}}{28}{figure.2.14}\protected@file@percent }
\newlabel{fig:TeacherForcing}{{2.14}{28}{Teacher Forcing ç¤ºæ„å›¾}{figure.2.14}{}}
\newlabel{fig:TeacherForcing@cref}{{[figure][14][2]2.14}{[1][28][]28}{}{}{}}
\newlabel{def:teacher-forcing}{{2.1.3}{28}{Step2:è®¡ç®—ç›¸å…³æ€§åˆ†æ•°å¹¶è¿›è¡ŒSoftmaxå½’ä¸€åŒ–}{tcb@cnt@Definition.6}{}}
\newlabel{def:teacher-forcing@cref}{{[subsection][3][2,1]2.1.3}{[1][28][]28}{}{}{}}
\newlabel{def:auto-regressive}{{2.1.3}{28}{Step2:è®¡ç®—ç›¸å…³æ€§åˆ†æ•°å¹¶è¿›è¡ŒSoftmaxå½’ä¸€åŒ–}{tcb@cnt@Definition.7}{}}
\newlabel{def:auto-regressive@cref}{{[subsection][3][2,1]2.1.3}{[1][28][]28}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{Step2:è®¡ç®—ç›¸å…³æ€§åˆ†æ•°å¹¶è¿›è¡ŒSoftmaxå½’ä¸€åŒ–}{28}{figure.caption.17}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Step2:è®¡ç®—ç›¸å…³æ€§åˆ†æ•°å¹¶è¿›è¡ŒSoftmaxå½’ä¸€åŒ–}}{28}{figure.caption.18}\protected@file@percent }
\newlabel{fig:Step2:è®¡ç®—ç›¸å…³æ€§åˆ†æ•°å¹¶è¿›è¡ŒSoftmaxå½’ä¸€åŒ–}{{2.13}{28}{Step2:è®¡ç®—ç›¸å…³æ€§åˆ†æ•°å¹¶è¿›è¡ŒSoftmaxå½’ä¸€åŒ–}{figure.caption.18}{}}
\newlabel{fig:Step2:è®¡ç®—ç›¸å…³æ€§åˆ†æ•°å¹¶è¿›è¡ŒSoftmaxå½’ä¸€åŒ–@cref}{{[figure][13][2]2.13}{[1][28][]28}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{Step3:ç”¨æ³¨æ„åŠ›æƒé‡å¯¹$ğ‘‰$æƒæ±‚å’Œï¼Œå¾—åˆ°è¾“å‡º}{29}{tcb@cnt@Definition.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces Step3:ç”¨æ³¨æ„åŠ›æƒé‡å¯¹$ğ‘‰$æƒæ±‚å’Œï¼Œå¾—åˆ°è¾“å‡º}}{29}{figure.caption.19}\protected@file@percent }
\newlabel{fig:Step3:ç”¨æ³¨æ„åŠ›æƒé‡å¯¹$ğ‘‰$æƒæ±‚å’Œï¼Œå¾—åˆ°è¾“å‡º}{{2.15}{29}{Step3:ç”¨æ³¨æ„åŠ›æƒé‡å¯¹$ğ‘‰$æƒæ±‚å’Œï¼Œå¾—åˆ°è¾“å‡º}{figure.caption.19}{}}
\newlabel{fig:Step3:ç”¨æ³¨æ„åŠ›æƒé‡å¯¹$ğ‘‰$æƒæ±‚å’Œï¼Œå¾—åˆ°è¾“å‡º@cref}{{[figure][15][2]2.15}{[1][29][]29}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.17}{\ignorespaces Multi-Head Attentionçš„è¾“å‡ºæ‹¼æ¥ç¤ºæ„å›¾}}{30}{figure.2.17}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.18}{\ignorespaces å¤šå¤´æ³¨æ„åŠ›è¾“å‡ºæ•´åˆå¹¶é€å…¥FFN}}{30}{figure.2.18}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step4: å¤šå¤´æ³¨æ„åŠ›çš„è¾“å‡ºåˆå¹¶}{30}{figure.caption.19}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces Multi-Head Attentionä¸­çš„$Q$,$K$,$V$åœ¨ä¸åŒHeadä¸­æ˜¯ç‹¬ç«‹çš„}}{30}{figure.caption.20}\protected@file@percent }
\newlabel{fig:Multi-Head Attentionè®¡ç®—å›¾}{{2.16}{30}{Multi-Head Attentionä¸­çš„$Q$,$K$,$V$åœ¨ä¸åŒHeadä¸­æ˜¯ç‹¬ç«‹çš„}{figure.caption.20}{}}
\newlabel{fig:Multi-Head Attentionè®¡ç®—å›¾@cref}{{[figure][16][2]2.16}{[1][30][]30}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{Step5: Add \& Norm}{31}{Item.30}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Layer Normalization}{31}{Item.30}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.19}{\ignorespaces \href  {http://proceedings.mlr.press/v119/shen20e/shen20e.pdf}{Layer Normalization vs. Batch Normalization} ç¤ºæ„å›¾}}{31}{figure.caption.21}\protected@file@percent }
\newlabel{fig:layernorm}{{2.19}{31}{\href {http://proceedings.mlr.press/v119/shen20e/shen20e.pdf}{Layer Normalization vs. Batch Normalization} ç¤ºæ„å›¾}{figure.caption.21}{}}
\newlabel{fig:layernorm@cref}{{[figure][19][2]2.19}{[1][31][]31}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.20}{\ignorespaces Residual Connection ç¤ºæ„å›¾}}{32}{figure.2.20}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Residual Connection}{32}{figure.caption.21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Point-wise Feed-Forward Network}{33}{tcb@cnt@Definition.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.21}{\ignorespaces Point-wise Feed-Forward Network}}{33}{figure.caption.24}\protected@file@percent }
\newlabel{fig:Point-wise Feed-Forward Network}{{2.21}{33}{Point-wise Feed-Forward Network}{figure.caption.24}{}}
\newlabel{fig:Point-wise Feed-Forward Network@cref}{{[figure][21][2]2.21}{[1][33][]33}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.22}{\ignorespaces Mask Matrix $M$ç¤ºæ„å›¾}}{34}{figure.2.22}\protected@file@percent }
\newlabel{fig:Masked Multi-Head Self-Attention}{{2.22}{34}{Mask Matrix $M$ç¤ºæ„å›¾}{figure.2.22}{}}
\newlabel{fig:Masked Multi-Head Self-Attention@cref}{{[figure][22][2]2.22}{[1][34][]34}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Decoder ç»“æ„}{34}{subsection.2.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Masked Multi-Head Self-Attention}{34}{subsection.2.1.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.23}{\ignorespaces Self-Attention vs. Masked Self-Attention}}{34}{figure.caption.26}\protected@file@percent }
\newlabel{fig:Self-Attention vs. Masked Self-Attention}{{2.23}{34}{Self-Attention vs. Masked Self-Attention}{figure.caption.26}{}}
\newlabel{fig:Self-Attention vs. Masked Self-Attention@cref}{{[figure][23][2]2.23}{[1][34][]34}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{Encoder-Decoder Attention(cross-attention)}{35}{figure.caption.26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Encoder-Decoder Attention (Cross-Attention)}{35}{figure.caption.26}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.24}{\ignorespaces Cross-Attention}}{35}{figure.caption.27}\protected@file@percent }
\newlabel{fig:Cross-Attention}{{2.24}{35}{Cross-Attention}{figure.caption.27}{}}
\newlabel{fig:Cross-Attention@cref}{{[figure][24][2]2.24}{[1][35][]35}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{è®­ç»ƒä¸æ¨ç†å·®å¼‚}{35}{figure.caption.27}\protected@file@percent }
\newlabel{def:logits}{{2.1.5}{36}{Output Projection \& Softmax}{tcb@cnt@Definition.9}{}}
\newlabel{def:logits@cref}{{[subsection][5][2,1]2.1.5}{[1][36][]36}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.5}Output Projection \& Softmax}{36}{subsection.2.1.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.25}{\ignorespaces Linear + Softmax}}{36}{figure.caption.28}\protected@file@percent }
\newlabel{fig:Linear + Softmax}{{2.25}{36}{Linear + Softmax}{figure.caption.28}{}}
\newlabel{fig:Linear + Softmax@cref}{{[figure][25][2]2.25}{[1][36][]36}{}{}{}}
\ttl@writefile{ptc}{\ttl@stoptoc{chapters@6}}
\ttl@writefile{ptc}{\ttl@starttoc{chapters@7}}
\newmarginnote{note.37.1}{{37}{2752512sp}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Memory Accounting}{37}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Tensors Basics}{37}{subsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Tensors Memory}{37}{subsection.2.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.27}{\ignorespaces FP32çš„ä¸€äº›ç‰¹æ€§}}{38}{figure.2.27}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{float32}{38}{tcb@cnt@Definition.13}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.26}{\ignorespaces float32 å†…å­˜ç»“æ„ç¤ºæ„å›¾}}{38}{figure.caption.29}\protected@file@percent }
\newlabel{fig:float32 å†…å­˜ç»“æ„ç¤ºæ„å›¾}{{2.26}{38}{float32 å†…å­˜ç»“æ„ç¤ºæ„å›¾}{figure.caption.29}{}}
\newlabel{fig:float32 å†…å­˜ç»“æ„ç¤ºæ„å›¾@cref}{{[figure][26][2]2.26}{[1][38][]38}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.30}{\ignorespaces ä¸‰ç§Data Typeçš„æ€§èƒ½æ¯”è¾ƒ}}{39}{figure.2.30}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{float16}{39}{figure.2.27}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.28}{\ignorespaces float16 å†…å­˜ç»“æ„ç¤ºæ„å›¾}}{39}{figure.caption.30}\protected@file@percent }
\newlabel{fig:float16 å†…å­˜ç»“æ„ç¤ºæ„å›¾}{{2.28}{39}{float16 å†…å­˜ç»“æ„ç¤ºæ„å›¾}{figure.caption.30}{}}
\newlabel{fig:float16 å†…å­˜ç»“æ„ç¤ºæ„å›¾@cref}{{[figure][28][2]2.28}{[1][39][]39}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{bfloat16}{39}{tcb@cnt@Definition.14}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.29}{\ignorespaces float16 å†…å­˜ç»“æ„ç¤ºæ„å›¾}}{39}{figure.caption.31}\protected@file@percent }
\newlabel{fig:float16 å†…å­˜ç»“æ„ç¤ºæ„å›¾}{{2.29}{39}{float16 å†…å­˜ç»“æ„ç¤ºæ„å›¾}{figure.caption.31}{}}
\newlabel{fig:float16 å†…å­˜ç»“æ„ç¤ºæ„å›¾@cref}{{[figure][29][2]2.29}{[1][39][]39}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{fp8}{40}{figure.2.30}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.31}{\ignorespaces fp8 å†…å­˜ç»“æ„ç¤ºæ„å›¾}}{40}{figure.caption.32}\protected@file@percent }
\newlabel{fig:fp8 å†…å­˜ç»“æ„ç¤ºæ„å›¾}{{2.31}{40}{fp8 å†…å­˜ç»“æ„ç¤ºæ„å›¾}{figure.caption.32}{}}
\newlabel{fig:fp8 å†…å­˜ç»“æ„ç¤ºæ„å›¾@cref}{{[figure][31][2]2.31}{[1][40][]40}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Comparison of common floating-point formats for deep learning}}{40}{table.caption.33}\protected@file@percent }
\newlabel{tab:fp_all_compare}{{2.2}{40}{Comparison of common floating-point formats for deep learning}{table.caption.33}{}}
\newlabel{tab:fp_all_compare@cref}{{[table][2][2]2.2}{[1][40][]40}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.32}{\ignorespaces FP32å’ŒFP16çš„æ€§èƒ½å¯¹æ¯”}}{41}{figure.2.32}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Mixed Precision Training \href  {https://arxiv.org/pdf/1710.03740.pdf}{[Micikevicius et al., 2017]}}{41}{subsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{æŠ€æœ¯èƒŒæ™¯}{41}{subsection.2.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.33}{\ignorespaces FP32 vs. FP16}}{41}{figure.caption.34}\protected@file@percent }
\newlabel{fig:FP32 vs. FP16}{{2.33}{41}{FP32 vs. FP16}{figure.caption.34}{}}
\newlabel{fig:FP32 vs. FP16@cref}{{[figure][33][2]2.33}{[1][41][]41}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{æ ¸å¿ƒæŒ‘æˆ˜â€”â€”FP16çš„ä½ç²¾åº¦å’ŒNarrow dynamic range:}{41}{figure.caption.34}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.35}{\ignorespaces Multibox SSD ç½‘ç»œè®­ç»ƒæ—¶æ¿€æ´»æ¢¯åº¦çš„åˆ†å¸ƒç›´æ–¹å›¾}}{42}{figure.2.35}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{æŠ€æœ¯è·¯å¾„}{42}{figure.caption.34}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{FP32 Master Copy of Weights}{42}{Item.37}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.34}{\ignorespaces Mixed precision training iteration for a layer.}}{42}{figure.caption.35}\protected@file@percent }
\newlabel{Mixed precision training iteration for a layer.}{{2.34}{42}{Mixed precision training iteration for a layer}{figure.caption.35}{}}
\newlabel{Mixed precision training iteration for a layer.@cref}{{[figure][34][2]2.34}{[1][42][]42}{}{}{}}
\@writefile{toc}{\contentsline {subparagraph}{Loss Scaling}{42}{figure.caption.35}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.36}{\ignorespaces Loss Scaling}}{42}{figure.caption.36}\protected@file@percent }
\newlabel{Loss Scaling}{{2.36}{42}{Loss Scaling}{figure.caption.36}{}}
\newlabel{Loss Scaling@cref}{{[figure][36][2]2.36}{[1][42][]42}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.38}{\ignorespaces AMP code example}}{43}{figure.2.38}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Arithmetic Precision}{43}{figure.caption.36}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.37}{\ignorespaces  FP16 å­˜å‚¨ã€Tensor Core å†…éƒ¨ FP32 multiply-accumulate çš„æ•°æ®æµç¤ºæ„ã€‚ è¾“å…¥å­˜å‚¨ä¸ºä½ç²¾åº¦ä»¥æé«˜ååï¼Œè®¡ç®—ä¸ç´¯åŠ åœ¨ç¡¬ä»¶å†…éƒ¨ä¿æŒé«˜ç²¾åº¦ä»¥ç¡®ä¿æ•°å€¼ç¨³å®šæ€§ã€‚ }}{43}{figure.caption.37}\protected@file@percent }
\newlabel{fig:arithmetic_precision}{{2.37}{43}{FP16 å­˜å‚¨ã€Tensor Core å†…éƒ¨ FP32 multiply-accumulate çš„æ•°æ®æµç¤ºæ„ã€‚ è¾“å…¥å­˜å‚¨ä¸ºä½ç²¾åº¦ä»¥æé«˜ååï¼Œè®¡ç®—ä¸ç´¯åŠ åœ¨ç¡¬ä»¶å†…éƒ¨ä¿æŒé«˜ç²¾åº¦ä»¥ç¡®ä¿æ•°å€¼ç¨³å®šæ€§ã€‚}{figure.caption.37}{}}
\newlabel{fig:arithmetic_precision@cref}{{[figure][37][2]2.37}{[1][43][]43}{}{}{}}
\@writefile{toc}{\contentsline {subparagraph}{AMP: Automatic Mixed Precision}{43}{figure.caption.37}\protected@file@percent }
\ttl@writefile{ptc}{\ttl@stoptoc{chapters@7}}
\ttl@writefile{ptc}{\ttl@starttoc{chapters@8}}
\newmarginnote{note.44.1}{{44}{13468164sp}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Compute Accounting}{44}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Tensors On Gpus}{44}{subsection.2.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.39}{\ignorespaces Move tensor from CPU to GPUs}}{44}{figure.caption.38}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Tensor Operations}{45}{subsection.2.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Tensor Storage}{45}{subsection.2.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.40}{\ignorespaces Tensor Storage}}{45}{figure.caption.39}\protected@file@percent }
\newlabel{fig:Tensor Storage}{{2.40}{45}{Tensor Storage}{figure.caption.39}{}}
\newlabel{fig:Tensor Storage@cref}{{[figure][40][2]2.40}{[1][45][]45}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{Tensor Slicing}{45}{lstnumber.-2.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Elementwise Operations}{46}{lstnumber.-3.37}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Matrix Multiplication}{46}{lstnumber.-4.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Tensor Einops}{48}{subsection.2.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Einops: Motivation}{48}{subsection.2.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Jaxtyping: Basics}{48}{lstnumber.-6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Einsum = Named MatMul with Bookkeeping}{48}{lstnumber.-7.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Einops: Reduce (èšåˆ)}{49}{lstnumber.-8.17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Einops: Rearrange + Einsumï¼ˆå±•å¼€/é‡æ’ + çº¿æ€§å˜æ¢ï¼‰}{49}{lstnumber.-9.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Tensor Operations Flops}{50}{subsection.2.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{çŸ©é˜µä¹˜æ³•çš„ FLOPs}{50}{subsection.2.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{å…¶ä»–å¸¸è§æ“ä½œçš„ FLOPs}{50}{subsection.2.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Transformer çš„è¿‘ä¼¼ FLOPs}{50}{subsection.2.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Model FLOPs Utilization (MFU)}{50}{subsection.2.3.4}\protected@file@percent }
\newlabel{def:mfu}{{2.3.4}{50}{Model FLOPs Utilization (MFU)}{tcb@cnt@Definition.15}{}}
\newlabel{def:mfu@cref}{{[subsection][4][2,3]2.3.4}{[1][50][]50}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.5}Gradients Basics}{51}{subsection.2.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{ç¤ºä¾‹ï¼šç®€å•çº¿æ€§æ¨¡å‹}{51}{subsection.2.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{è¦ç‚¹æ€»ç»“}{51}{lstnumber.-11.19}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.6}Gradients Flops}{52}{subsection.2.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Forward FLOPs}{52}{lstnumber.-12.9}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Backward FLOPs (ç¤ºä¾‹ï¼š$w_2$)}{52}{lstnumber.-12.9}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Backward FLOPsï¼ˆç¤ºä¾‹ï¼š$w_1$ï¼‰}{52}{lstnumber.-12.9}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{æ€» FLOPs å…¬å¼}{52}{lstnumber.-12.9}\protected@file@percent }
\ttl@writefile{ptc}{\ttl@stoptoc{chapters@8}}
\ttl@writefile{ptc}{\ttl@starttoc{chapters@9}}
\newmarginnote{note.53.1}{{53}{2752512sp}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Models}{53}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Module Parameters \& Parameters Initialization}{53}{subsection.2.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Parameter Initialization}{53}{subsection.2.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Custom Deep Linear Model}{54}{subsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Design idea.}{54}{subsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Code implementation.}{54}{subsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Example: building and checking the model.}{54}{lstnumber.-15.28}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Parameter count formula.}{55}{lstnumber.-16.14}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Connecting to FLOPs.}{55}{lstnumber.-16.14}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Mini workflow (from build to one training step)}{55}{lstnumber.-16.14}\protected@file@percent }
\ttl@writefile{ptc}{\ttl@stoptoc{chapters@9}}
\ttl@writefile{ptc}{\ttl@starttoc{chapters@10}}
\newmarginnote{note.56.1}{{56}{13468164sp}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Training Loop And Best Practices}{56}{section.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Data Loading for Language Modeling}{56}{subsection.2.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Batch Sampling Utility}{57}{subsection.2.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{What this does (step-by-step).}{57}{lstnumber.-20.12}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Usage.}{57}{lstnumber.-20.12}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Notes and practical tips.}{57}{lstnumber.-21.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Pinned memory for faster GPU transfer.}{58}{lstnumber.-21.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Pipeline overlap.}{58}{lstnumber.-22.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}Optimizer}{59}{subsection.2.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Recap and relationships.}{59}{subsection.2.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Code: AdaGrad on our model.}{59}{lstnumber.-23.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Memory accounting for one training step.}{61}{tcb@cnt@Definition.16}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{FLOPs for one step.}{61}{tcb@cnt@Definition.16}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Train-loop}{62}{section.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{æµç¨‹è¯´æ˜ã€‚}{62}{lstnumber.-25.33}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Checkpointing (Save/Load)}{63}{section.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{è¦ç‚¹ä¸å®è·µæç¤ºã€‚}{63}{lstnumber.-26.21}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Modern Models' Architecture}}{65}{figure.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Architectures variations \& Hyperparameters \& Stability tricks}{65}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\ttl@writefile{ptc}{\ttl@stoptoc{chapters@10}}
\ttl@writefile{ptc}{\ttl@starttoc{chapters@11}}
\newmarginnote{note.65.1}{{65}{2752512sp}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}The Original Transformer \& Modern Variants}{65}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Review of the Original Transformer}{65}{subsection.3.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces The original Transformer architecture}}{65}{figure.caption.40}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Pre-norm vs. Post-norm in residual flow}}{66}{figure.3.3}\protected@file@percent }
\newlabel{fig:fig3.3}{{3.3}{66}{Pre-norm vs. Post-norm in residual flow}{figure.3.3}{}}
\newlabel{fig:fig3.3@cref}{{[figure][3][3]3.3}{[1][66][]66}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Performance of the models with different learning rate and $T_{\text  {warm-up}}$}}{66}{figure.3.5}\protected@file@percent }
\newlabel{fig:lec3.05}{{3.5}{66}{Performance of the models with different learning rate and $T_{\text {warm-up}}$}{figure.3.5}{}}
\newlabel{fig:lec3.05@cref}{{[figure][5][3]3.5}{[1][66][]66}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Normalization Variants}{66}{subsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Pre-norm vs. Post-norm in Transformer}{66}{figure.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Post-LN Transformer v.s. Pre-LN Transformer}}{66}{figure.caption.41}\protected@file@percent }
\newlabel{fig:}{{3.4}{66}{Post-LN Transformer v.s. Pre-LN Transformer}{figure.caption.41}{}}
\newlabel{fig:@cref}{{[figure][4][3]3.4}{[1][66][]66}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{1. Pre-LayerNorm å¯ä»¥å»é™¤æ¨¡å‹å¯¹äºwarm-upé˜¶æ®µçš„ä¾èµ–}{66}{figure.caption.41}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Development BLEU on enâ†’vi with POSTNORM or PRENORM, and with LAYERNORM or SCALENORM.}}{67}{figure.caption.42}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{2. Pre-LayerNorm å¯ä»¥ç¼“è§£æ¢¯åº¦çˆ†ç‚¸é—®é¢˜}{68}{tcb@cnt@Proposition.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Gradient Attenuation by Pre-LN}}{68}{figure.caption.43}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Gradient Spikes}}{68}{figure.caption.44}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{3. Pre-LayerNorm å¯ä»¥æé«˜æ•´ä½“çš„ç¨³å®šæ€§å¹¶æé«˜Learning RateåŠ é€Ÿæ”¶æ•›}{68}{figure.caption.44}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Performances of the models with pre-norm or post-norm}}{68}{figure.caption.45}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Double Norm}{69}{figure.caption.45}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces Transformer with double layernorm }}{69}{figure.caption.46}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Proportion of FLOPs across different operations}}{70}{figure.3.11}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces Proportion of Runtime across different operations}}{70}{figure.3.12}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.13}{\ignorespaces FLOPS and FLOP-to-memory ratio in Transformer}}{70}{figure.3.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{LayerNorm vs. RMSNorm}{70}{figure.caption.46}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.14}{\ignorespaces RMSNorm runtime}}{70}{figure.caption.47}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.15}{\ignorespaces ReLU vs. GELU}}{72}{figure.3.15}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.16}{\ignorespaces GLUE Language-Understanding Benchmark}}{72}{figure.3.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Activation Variants}{72}{subsection.3.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{A few of the common activations}{72}{subsection.3.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Gated activations(*GLU)}{72}{AMS.51}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}Serial vs. Parallel layers}{73}{subsection.3.1.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.17}{\ignorespaces A transformer block in original transformer}}{73}{figure.caption.52}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.5}RoPE: Rotary Position Embeddings}{74}{subsection.3.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{A few of commom embeddings}{74}{subsection.3.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{High level thought process: Relativity }{74}{subsection.3.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{RoPE: rotary position embeddings}{75}{subsection.3.1.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.18}{\ignorespaces Implementation of Rotary Position Embedding(RoPE).}}{76}{figure.caption.53}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{General form}{76}{figure.caption.53}\protected@file@percent }
\newlabel{fn:rope-fqk}{{3.1.5}{76}{General form}{figure.caption.53}{}}
\newlabel{fn:rope-fqk@cref}{{[subsection][5][3,1]3.1.5}{[1][76][]76}{}{}{}}
\newlabel{fn:rope-RMat}{{3.1.5}{76}{General form}{figure.caption.53}{}}
\newlabel{fn:rope-RMat@cref}{{[subsection][5][3,1]3.1.5}{[1][76][]76}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.19}{\ignorespaces Implementation and code for RoPE}}{77}{figure.3.19}\protected@file@percent }
\newlabel{fn:rope-qk}{{3.1}{77}{General form}{equation.3.1}{}}
\newlabel{fn:rope-qk@cref}{{[equation][1][3]3.1}{[1][76][]77}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.6}Properties of RoPE}{77}{subsection.3.1.6}\protected@file@percent }
\newlabel{sec:prop-of-RoPE}{{3.1.6}{77}{Properties of RoPE}{subsection.3.1.6}{}}
\newlabel{sec:prop-of-RoPE@cref}{{[subsection][6][3,1]3.1.6}{[1][77][]77}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{é•¿ç¨‹è¡°å‡ (Long-term decay).}{77}{subsection.3.1.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{ç»“åˆçº¿æ€§æ³¨æ„åŠ› (RoPE with linear attention).}{77}{subsection.3.1.6}\protected@file@percent }
\newlabel{fn:atten-full}{{3.2}{77}{ç»“åˆçº¿æ€§æ³¨æ„åŠ› (RoPE with linear attention)}{equation.3.2}{}}
\newlabel{fn:atten-full@cref}{{[equation][2][3]3.2}{[1][77][]77}{}{}{}}
\newlabel{fn:linear-attention}{{3.3}{77}{ç»“åˆçº¿æ€§æ³¨æ„åŠ› (RoPE with linear attention)}{equation.3.3}{}}
\newlabel{fn:linear-attention@cref}{{[equation][3][3]3.3}{[1][77][]77}{}{}{}}
\newlabel{fn:linear-rope}{{3.4}{77}{ç»“åˆçº¿æ€§æ³¨æ„åŠ› (RoPE with linear attention)}{equation.3.4}{}}
\newlabel{fn:linear-rope@cref}{{[equation][4][3]3.4}{[1][77][]77}{}{}{}}
\@writefile{toc}{\contentsline {paragraph}{è¯´æ˜.}{77}{equation.3.4}\protected@file@percent }
\ttl@writefile{ptc}{\ttl@stoptoc{chapters@11}}
\ttl@writefile{ptc}{\ttl@starttoc{chapters@12}}
\newmarginnote{note.78.1}{{78}{13468164sp}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Hyperparameters}{78}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Feedforward Dimension Ratio}{78}{subsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Exception 1 - GLU variants}{78}{equation.3.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.20}{\ignorespaces Examples of GLU Dimensions}}{78}{figure.caption.54}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Exception 2 - T5}{79}{figure.caption.54}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.21}{\ignorespaces Reason for the 64-multipliers in T-5 Model}}{79}{figure.caption.55}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.22}{\ignorespaces The range of the ratio}}{79}{figure.caption.56}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Head Dimension, Heads number and Model Dimension}{80}{subsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{è®¡ç®—ä¸Šçš„ç›´è§‚ç†è§£.}{80}{subsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Head-dim ä¸ Model-dim çš„æ¯”ç‡.}{80}{subsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{ä¸ºä½•ä¸æ˜¯å¿…é¡»ï¼Ÿ}{80}{subsection.3.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.23}{\ignorespaces Most models have ratios around 1.}}{80}{figure.caption.57}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.24}{\ignorespaces Deep models are hard to parallelize}}{81}{figure.3.24}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Aspect Ratio}{81}{subsection.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{ç›´è§‚ç†è§£.}{81}{figure.3.24}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.25}{\ignorespaces Loss Increase vs. Aspect Ratio$(d_{model}/n_{layer})$}}{81}{figure.caption.58}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Vocabulary Size}{82}{subsection.3.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.26}{\ignorespaces Vocabulary Examples}}{82}{figure.caption.59}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.5}Regularization}{82}{subsection.3.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Dropout and weigty decay in practice}{82}{tcb@cnt@Definition.23}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.27}{\ignorespaces Dropout and weight decay Examples}}{83}{figure.3.27}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.28}{\ignorespaces æƒé‡è¡°å‡ï¼ˆWeight Decayï¼‰åœ¨å¤§è§„æ¨¡é¢„è®­ç»ƒä¸­å¹¶ä¸æ˜¯ç”¨æ¥é˜²æ­¢è¿‡æ‹Ÿåˆçš„ã€‚ å¦‚å›¾æ‰€ç¤ºï¼Œä¸åŒçš„ $\mitlambda _{WD}$ å¯¹è®­ç»ƒæŸå¤±ä¸éªŒè¯æŸå¤±çš„å·®è·å‡ ä¹æ²¡æœ‰å½±å“ï¼Œ è¯´æ˜å…¶ä¸»è¦ä½œç”¨å¹¶éæ§åˆ¶è¿‡æ‹Ÿåˆï¼Œè€Œæ˜¯å½±å“ä¼˜åŒ–åŠ¨æ€ã€‚}}{83}{figure.caption.60}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.29}{\ignorespaces \textbf  {Weight decay interacts with learning rates(cosine schedule)} åœ¨ä½™å¼¦é€€ç« (cosine LR decay, å·¦) å’Œå¸¸æ•°å­¦ä¹ ç‡ (constant LR, å³) ä¸‹ï¼Œ ä¸åŒ $\mitlambda _{WD}$ å¯¼è‡´äº†æ˜æ˜¾ä¸åŒçš„æ”¶æ•›è½¨è¿¹ã€‚ è¿™è¡¨æ˜ Weight Decay æ›´åƒæ˜¯ä¸€ç§ä¼˜åŒ–è°ƒèŠ‚å™¨ï¼Œè€Œéå•çº¯çš„æ­£åˆ™åŒ–æ‰‹æ®µã€‚}}{83}{figure.caption.61}\protected@file@percent }
\ttl@writefile{ptc}{\ttl@stoptoc{chapters@12}}
\ttl@writefile{ptc}{\ttl@starttoc{chapters@13}}
\newmarginnote{note.84.1}{{84}{13468164sp}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Stability tricks}{84}{section.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.30}{\ignorespaces è®­ç»ƒè¿‡ç¨‹ä¸­ loss vs. L2 Gradient}}{84}{figure.caption.62}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Output Softmax Stability}{84}{subsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{åŸå› åˆ†æ.}{84}{subsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{ç¼“è§£æ–¹æ³•.}{85}{subsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Softmax å®šä¹‰.}{85}{subsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{å–å¯¹æ•°.}{85}{subsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{åŸå§‹æŸå¤±å‡½æ•°.}{85}{subsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{åŠ å…¥æ­£åˆ™é¡¹.}{85}{subsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{æ¨å¯¼æµç¨‹å›¾.}{85}{subsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Attention Softmax Stability - the QK norm}{86}{subsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\textbf  {Motivation}}{86}{subsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Query-Key Normalization(QK-Norm)}{86}{subsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{With QK-Norm}{86}{subsection.3.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.31}{\ignorespaces Transformer Architecture with QK norm}}{87}{figure.caption.63}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Difference with Usual Normalization.}{87}{figure.caption.63}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Logit Soft-Capping}{87}{subsection.3.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Effect on Attention.}{87}{tcb@cnt@Definition.26}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Comparison with QK-Norm.}{88}{tcb@cnt@Definition.26}\protected@file@percent }
\ttl@writefile{ptc}{\ttl@stoptoc{chapters@13}}
\ttl@writefile{ptc}{\ttl@starttoc{chapters@14}}
\newmarginnote{note.89.1}{{89}{2752512sp}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Attention Heads}{89}{section.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Grouped-Query Attention \& Multi-Query Attention}{89}{subsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Motivation.}{89}{subsection.3.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.32}{\ignorespaces Computation in attention}}{89}{figure.caption.64}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Arithmetic Intensity.}{89}{figure.caption.64}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Arithmetic Operations.}{90}{tcb@cnt@Proposition.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Memory Accesses.}{90}{tcb@cnt@Proposition.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Conclusion.}{90}{tcb@cnt@Proposition.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Challenge.}{91}{tcb@cnt@Proposition.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Solution: KV Cache.}{91}{tcb@cnt@Proposition.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{Summary.}{91}{tcb@cnt@Proposition.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.33}{\ignorespaces KV Cacheç¤ºæ„å›¾ï¼Œä¸Šä¸€æ’æ˜¯without KV cache, ä¸‹ä¸€æ’æ˜¯with KV Cache.}}{91}{figure.caption.65}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{MQAï¼ˆMulti-Query Attentionï¼‰}{92}{figure.caption.65}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.34}{\ignorespaces MQA ç¤ºæ„å›¾}}{92}{figure.caption.66}\protected@file@percent }
\@writefile{toc}{\contentsline {subparagraph}{MQA çš„æ€æƒ³}{92}{figure.caption.66}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{GQAï¼ˆGrouped-Query Attentionï¼‰â€”æŒ‰ slide çš„æ€»é‡}{93}{figure.caption.66}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.35}{\ignorespaces GQAç¤ºæ„å›¾}}{93}{figure.caption.67}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Sparse/Sliding Window Attention}{94}{subsection.3.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.36}{\ignorespaces Sparse / Sliding window attention ç¤ºæ„å›¾}}{94}{figure.caption.68}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.37}{\ignorespaces Sliding window attention ç¤ºæ„å›¾. \textbf  {Just use the main part of the strided pattern.}}}{94}{figure.caption.69}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Current standard trick - interleave 'full' and 'LR' attention.}{95}{figure.caption.69}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.38}{\ignorespaces Standard trick ç¤ºæ„å›¾}}{95}{figure.caption.70}\protected@file@percent }
\ttl@finishall
\gdef \@abspage@last{95}
